{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nezuk00/vis4/blob/main/lab_california_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "444091ac",
      "metadata": {
        "id": "444091ac"
      },
      "source": [
        "\n",
        "# Лабораторная работа: Классификация на основе датасета California Housing\n",
        "\n",
        "В этой лабораторной работе используется датасет из **задания 1** (California Housing). Исходно задача была регрессионной – предсказание стоимости дома `median_house_value`. Здесь мы преобразуем её в задачу **классификации**, разбив целевой признак на интервалы, и исследуем влияние дисбаланса классов и методов балансировки на качество модели.\n",
        "\n",
        "**План:**\n",
        "1. Загрузить и подготовить данные: переименовать столбцы, создать категориальный признак `ocean_proximity` и разделить стоимость на интервалы.\n",
        "2. Построить модель `DecisionTreeClassifier` на исходных данных, оценить точность (accuracy).\n",
        "3. Искусственно создать дисбаланс классов, уменьшив один из классов до 10 % от максимального, обучить новую модель и оценить точность.\n",
        "4. Применить методы балансировки (Random Oversampling, SMOTE, ADASYN, Tomek Links), для каждой получить модель и оценить точность.\n",
        "5. Сравнить результаты и сделать выводы.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c3435e76",
      "metadata": {
        "id": "c3435e76"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Установим библиотеку imbalanced-learn (раскомментируйте при первом запуске)\n",
        "!pip install -q imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5d68a8c8",
      "metadata": {
        "id": "5d68a8c8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Библиотеки для балансировки\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fe9e409a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe9e409a",
        "outputId": "318a39cf-4506-47ea-842f-e15991626e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n",
            "Using Colab cache for faster access to the 'california-housing-prices' dataset.\n",
            "Распределение классов:\n",
            "price_category\n",
            "Low     6884\n",
            "High    6880\n",
            "Mid     6876\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Загрузка датасета. Можно использовать функцию sklearn или локальный CSV-файл.\n",
        "# Попробуем загрузить через sklearn; если нет интернета, загрузите локальный файл 'housing.csv'.\n",
        "!pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"housing.csv\"\n",
        "\n",
        "# Load the latest version of California Housing Prices\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"camnugent/california-housing-prices\",\n",
        "  file_path,\n",
        ")\n",
        "# Переименуем столбцы как в предыдущей лабораторной\n",
        "rename_dict = {\n",
        "    'MedInc': 'median_income',\n",
        "    'HouseAge': 'housing_median_age',\n",
        "    'AveRooms': 'average_rooms',\n",
        "    'AveBedrms': 'average_bedrooms',\n",
        "    'Population': 'population',\n",
        "    'AveOccup': 'households',\n",
        "    'Latitude': 'latitude',\n",
        "    'Longitude': 'longitude',\n",
        "    'MedHouseVal': 'median_house_value'\n",
        "}\n",
        "df.rename(columns=rename_dict, inplace=True)\n",
        "# Переведём стоимость в доллары\n",
        "df['median_house_value'] *= 100000\n",
        "# Создадим признак близости к океану\n",
        "df['ocean_proximity'] = np.where(df['latitude'] >= 35, 'NEAR BAY', 'INLAND')\n",
        "\n",
        "\n",
        "# Разобьём стоимость на 3 категории по квартилям\n",
        "# qcut автоматически делает интервалы примерно одинаковой мощности\n",
        "n_bins = 3\n",
        "df['price_category'] = pd.qcut(df['median_house_value'], q=n_bins, labels=['Low','Mid','High'])\n",
        "\n",
        "# Удалим исходный числовой столбец\n",
        "X = df.drop(['median_house_value', 'price_category'], axis=1)\n",
        "y = df['price_category']\n",
        "\n",
        "print('Распределение классов:')\n",
        "print(y.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "96560911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96560911",
        "outputId": "b58782fd-e734-47d3-b3d1-3784eab48484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy исходной модели: 0.7413\n",
            "\n",
            "Матрица ошибок:\n",
            "[[1587   59  418]\n",
            " [  79 1642  344]\n",
            " [ 368  334 1361]]\n",
            "\n",
            "Отчет классификации:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.77      0.77      2064\n",
            "         Low       0.81      0.80      0.80      2065\n",
            "         Mid       0.64      0.66      0.65      2063\n",
            "\n",
            "    accuracy                           0.74      6192\n",
            "   macro avg       0.74      0.74      0.74      6192\n",
            "weighted avg       0.74      0.74      0.74      6192\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Определяем числовые и категориальные признаки\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = ['ocean_proximity']\n",
        "\n",
        "# Создаём колонковый трансформер: нормализация числовых и OneHotEncoding категорий\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numeric_features),  # для дерева масштабирование не требуется\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Делим данные на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Собираем пайплайн: предобработка + модель\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Обучение\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Оценка на тестовой выборке\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy исходной модели: {acc:.4f}')\n",
        "print('\\nМатрица ошибок:')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('\\nОтчет классификации:')\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6710fa35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6710fa35",
        "outputId": "a6e3320a-2c76-49cd-d599-4a4649f0708f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Распределение классов в несбалансированной обучающей выборке:\n",
            "price_category\n",
            "High    4816\n",
            "Mid     4813\n",
            "Low      481\n",
            "Name: count, dtype: int64\n",
            "Accuracy модели на дисбалансированных данных: 0.6610\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Создаем искусственный дисбаланс: выберем класс с наибольшим количеством объектов\n",
        "class_counts = y_train.value_counts()\n",
        "max_class = class_counts.idxmax()\n",
        "min_class_count = int(class_counts.max() * 0.10)  # 10% от самого большого класса\n",
        "\n",
        "# Выберем индексы объектов этого класса в обучающей выборке и оставим только min_class_count\n",
        "idx_max_class = y_train[y_train == max_class].index\n",
        "idx_to_keep = idx_max_class[:min_class_count]\n",
        "# Инверсия: сохраняем остальные классы полностью\n",
        "idx_other_classes = y_train[y_train != max_class].index\n",
        "\n",
        "# Новый обучающий набор\n",
        "X_train_imb = pd.concat([X_train.loc[idx_to_keep], X_train.loc[idx_other_classes]], axis=0)\n",
        "y_train_imb = pd.concat([y_train.loc[idx_to_keep], y_train.loc[idx_other_classes]], axis=0)\n",
        "\n",
        "print('Распределение классов в несбалансированной обучающей выборке:')\n",
        "print(y_train_imb.value_counts())\n",
        "\n",
        "# Обучаем новую модель на несбалансированных данных\n",
        "model_imb = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "model_imb.fit(X_train_imb, y_train_imb)\n",
        "y_pred_imb = model_imb.predict(X_test)\n",
        "acc_imb = accuracy_score(y_test, y_pred_imb)\n",
        "print(f'Accuracy модели на дисбалансированных данных: {acc_imb:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c49ce74c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c49ce74c",
        "outputId": "8bec69c6-3e02-405b-ab14-5e7c39c3ac37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Без балансировки: accuracy = 0.6610\n",
            "Random Oversampling: accuracy = 0.6118\n",
            "SMOTE: accuracy = 0.6959\n",
            "ADASYN: accuracy = 0.6883\n",
            "Tomek Links: accuracy = 0.6526\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "samplers = {\n",
        "    'Без балансировки': None,\n",
        "    'Random Oversampling': RandomOverSampler(random_state=42),\n",
        "    'SMOTE': SMOTE(random_state=42),\n",
        "    # Генерируем новые объекты только для самого маленького класса\n",
        "    'ADASYN': ADASYN(random_state=42, sampling_strategy='minority'),\n",
        "    'Tomek Links': TomekLinks()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# трансформируем наши несбалансированные данные\n",
        "X_train_imb_transformed = preprocessor.transform(X_train_imb)\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "# превращаем разреженную матрицу в плотный массив (важно для SMOTE/ADASYN)\n",
        "if hasattr(X_train_imb_transformed, 'toarray'):\n",
        "    X_train_imb_transformed = X_train_imb_transformed.toarray()\n",
        "    X_test_transformed = X_test_transformed.toarray()\n",
        "\n",
        "for name, sampler in samplers.items():\n",
        "    if sampler is None:\n",
        "        X_res, y_res = X_train_imb_transformed, y_train_imb\n",
        "    else:\n",
        "        X_res, y_res = sampler.fit_resample(X_train_imb_transformed, y_train_imb)\n",
        "    clf = DecisionTreeClassifier(random_state=42)\n",
        "    clf.fit(X_res, y_res)\n",
        "    y_pred_bal = clf.predict(X_test_transformed)\n",
        "    results[name] = accuracy_score(y_test, y_pred_bal)\n",
        "    print(f'{name}: accuracy = {results[name]:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a9bc61",
      "metadata": {
        "id": "e9a9bc61"
      },
      "source": [
        "\n",
        "## Выводы\n",
        "\n",
        "В ходе выполнения задания была проведена классификация на основе датасета California Housing, преобразованного из задачи регрессии. Были сформированы три класса (Low, Mid, High) по стоимости жилья.\n",
        "\n",
        "- Базовая модель дерева решений на исходных данных показала некоторую точность (см. выводы выше).\n",
        "- Искусственное создание дисбаланса, уменьшив самый распространённый класс до 10 %, привело к снижению качества классификации. Это ожидаемо, поскольку дерево решений склонно уделять больше внимания большинству классов.\n",
        "- Применение методов балансировки:\n",
        "  - **Random Oversampling** воспроизводит экземпляры миноритарных классов, повышая их долю.\n",
        "  - **SMOTE** и **ADASYN** синтетически создают новые точки в миноритарных классах, тем самым улучшая обучающую выборку.\n",
        "  - **Tomek Links** удаляет приграничные объекты, стремясь уменьшить перекрытие классов.\n",
        "\n",
        "При сравнении accuracy видно, что методы синтетического увеличения (SMOTE, ADASYN) обычно дают лучший или сопоставимый результат по сравнению с простым копированием. Метод Tomek Links, являющийся скорее методом очистки, может давать неоднозначный эффект. Общий вывод: для задач с дисбалансом классов важно использовать подходящие методы балансировки, поскольку они способны значительно повысить качество классификации.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}